{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8152a95-ed79-4df2-8480-5fc4d42b5947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from bioinfokit import analys, visuz\n",
    "import os \n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from src.config import intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38b34f4",
   "metadata": {},
   "source": [
    "### Define directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "Base='/home/projects/cpr_10006/people/lilniu/projects/target/data/data_genotype/subset/Formatted/plink_qc4/gemma/'\n",
    "result_path = Base + 'results/'\n",
    "figure_path = Base + 'analysis/figures/'\n",
    "annotation_path = Base + 'analysis/annotation/'\n",
    "crossref_path = Base + 'analysis/cross_reference'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dde05c0",
   "metadata": {},
   "source": [
    "### Read summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2060d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read summary statistics after filtering for genome-wide significance (<5x10-8)\n",
    "sig_folder = 'sig/'\n",
    "os.chdir(os.path.join(result_path,sig_folder))\n",
    "my_files = glob.glob('*.txt')\n",
    "files = []\n",
    "for i in tqdm(my_files):\n",
    "    df = pd.read_csv(os.path.join(result_path,sig_folder,i), sep='\\t').drop(['Unnamed: 0'], axis=1)\n",
    "    files.append(df)\n",
    "    \n",
    "# Check if any file is missing\n",
    "print('Numer of files: {}'.format(len(my_files)))\n",
    "missing_files = [i for i in np.arange(1,421) if i not in sorted([int(i.split('_')[0]) for i in my_files])]\n",
    "print('Missing file:'.format(missing_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb13e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all significant hits\n",
    "df_sig = pd.concat(files)\n",
    "\n",
    "# Check if any reference and alternative SNPs are flipped\n",
    "df_sig['REF'] = df_sig['rs'].str.split('_').str[2]\n",
    "df_sig['ALT'] = df_sig['rs'].str.split('_').str[3]\n",
    "flipped = df_sig[df_sig['REF']!= df_sig['allele0']]\n",
    "print('Reference and alternative SNPs were flipped in the following rows: {}'.format(flipped))\n",
    "\n",
    "# Create two new columns of 'Protein ID' and 'Gene name' by splitting 'phenotype'\n",
    "df_sig['Protein ID'] = df_sig['phenotype'].str.split('_').str[0]\n",
    "df_sig['Gene name'] = df_sig['phenotype'].str.split('_').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee01b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check inflation factor lambda\n",
    "# script: https://github.com/pgxcentre/lambda/blob/master/compute_lambda.py\n",
    "lambda_log = pd.read_csv(os.path.join(result_path,'assoc/log.lambda.txt'), sep=' ',header=None, )\n",
    "lambda_log[3].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2a5751",
   "metadata": {},
   "source": [
    "### Export variants to be annotated by variant effect predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436107b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for VEP annotation\n",
    "target5_bim = pd.read_csv(os.path.join(Base,'target5.bim'), sep='\\s+', header=None, \n",
    "            names=['CHR', 'SNP', 'dummy', 'POS', 'ALT', 'REF'])\n",
    "target5_bim['allele']=target5_bim['REF']+'/'+target5_bim['ALT']\n",
    "target5_bim['strand']='+'\n",
    "target5_bim_sig = target5_bim[target5_bim['SNP'].isin(df_sig['rs'])]\n",
    "vep_input = target5_bim_sig[['CHR', 'POS', 'POS', 'allele','strand', 'SNP']]\n",
    "vep_input.to_csv(os.path.join(Base, 'target5.vep.input'), sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6564de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://grch37.ensembl.org/Homo_sapiens/Tools/VEP with RefSeq transcripts as reference\n",
    "# Read VEP annotation\n",
    "vep_output = pd.read_csv(os.path.join(Base, 'target5.vep.output.txt'), sep='\\t', na_values='-', low_memory=False)\n",
    "\n",
    "# Create a dictionary that matches SNP to rsID\n",
    "rsid = vep_output[['#Uploaded_variation', 'Existing_variation']].drop_duplicates()\n",
    "IDmapping_snp_to_rs = dict(zip(rsid['#Uploaded_variation'], rsid['Existing_variation'].str.split(',').str[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247748d4",
   "metadata": {},
   "source": [
    "### Primary pQTLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd22b315",
   "metadata": {},
   "source": [
    "#### Read clump results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02318525",
   "metadata": {},
   "source": [
    "- physical distance (±1 Mb) and LD threshold of r2 > 0.2, significance level 5e-8\n",
    "- check script \n",
    "/home/projects/cpr_10006/people/lilniu/projects/target/data/data_genotype/subset/Formatted/plink_qc4/gemma/analysis/script_clump.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary that matches phenotype ID and Protein ID\n",
    "phenotype_to_proteinID = pd.read_csv(os.path.join(Base,'ProteinID.txt'), sep='\\t')\n",
    "IDmapping_phenotype_to_proteinID = dict(zip(phenotype_to_proteinID['Phenotype ID'], phenotype_to_proteinID['Protein ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be19b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine clumped results for all proteins\n",
    "clump_path = result_path + 'assoc/clump_results/'\n",
    "os.chdir(clump_path)\n",
    "clump_files = glob.glob('*.clumped')\n",
    "\n",
    "files = [pd.read_csv(file, sep='\\s+') for file in clump_files]\n",
    "\n",
    "for df, file in zip(files, clump_files):\n",
    "    phenotype = int(file.split('.')[0])\n",
    "    proteinID = IDmapping_phenotype_to_proteinID[phenotype]\n",
    "    df['phenotype'] = proteinID\n",
    "    \n",
    "clumped_snps = pd.concat(files, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36d5a0b",
   "metadata": {},
   "source": [
    "#### Clumping of the HLA region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196dfaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude HLA region (chr6: 29691116–33054976)\n",
    "df = clumped_snps.copy()\n",
    "hla_region = (df.CHR == 6) & (df.BP > 29691116) & (df.BP < 33054976)\n",
    "clumped_hlaremoved = df[~hla_region]\n",
    "\n",
    "# identify the index of the SNP with the smallest p-value for each protein in the HLA region\n",
    "df_hla = df[hla_region]\n",
    "to_keep = df_hla.groupby('phenotype')['P'].idxmin()\n",
    "\n",
    "# filter out the SNPs from the HLA region and keep the selected SNPs with the smallest p-value\n",
    "clumped_refined = pd.concat([clumped_hlaremoved, df.query('index in @to_keep')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d768a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of significant associations, proteins, and SNPs\n",
    "gw_sig_threshold = 5e-8\n",
    "study_wide_sig_threshold = gw_sig_threshold / 420\n",
    "\n",
    "for threshold_type, threshold in [('genome-wide', gw_sig_threshold), ('study-wide', study_wide_sig_threshold)]:\n",
    "    significant = clumped_refined['P'] < threshold\n",
    "    nr_associations = significant.sum()\n",
    "    nr_proteins = clumped_refined.loc[significant, 'phenotype'].nunique()\n",
    "    nr_snps = clumped_refined.loc[significant, 'SNP'].nunique()\n",
    "    print(f\"At {threshold_type} significance threshold,\\nafter clump and HLA region removed,\\n{nr_associations} primary associations were identified,\\ninvolving {nr_proteins} proteins, and \\n{nr_snps} SNPs\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac74fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the ids for primary associations\n",
    "in_both = intersection(df_sig.set_index(['rs', 'phenotype']).index, clumped_refined.set_index(['SNP', 'phenotype']).index)\n",
    "df_sig_primary = df_sig.set_index(['rs','phenotype']).loc[in_both].reset_index()\n",
    "\n",
    "# Compute additional columns\n",
    "df_sig_primary = df_sig_primary.assign(maf=[a if a <0.5 else 1-a for a in df_sig_primary['af']])\n",
    "df_sig_primary = df_sig_primary.assign(beta_abs=abs(df_sig_primary['beta']))\n",
    "df_sig_primary = df_sig_primary.assign(maf_log10=np.log10(df_sig_primary.maf))\n",
    "df_sig_primary = df_sig_primary.assign(beta_abs_log10=[np.log10(a) for a in df_sig_primary['beta_abs']])\n",
    "df_sig_primary['rsID']=df_sig_primary['rs'].map(IDmapping_snp_to_rs)\n",
    "\n",
    "# Save data\n",
    "df_sig_primary.to_csv(os.path.join(Base,'analysis/dataset/df_sig_primary.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3019e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_sig_primary[df_sig_primary['phenotype']=='P22891_PROZ']['rsID']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881379c6",
   "metadata": {},
   "source": [
    "#### Assess post-clump pair-wise LD between primary pQTLs of the same protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dc8840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LD results\n",
    "# plink --file target5_primary_out --r2 --ld-window 99999 --ld-window-kb 99999 --ld-window-r2 0\n",
    "file = '/home/projects/cpr_10006/people/lilniu/projects/target/data/data_genotype/subset/Formatted/plink_qc4/plink.ld'\n",
    "df_ld = pd.read_csv(file, sep='\\s+')\n",
    "\n",
    "nr_snps = len(set(df_ld['SNP_A'].unique().tolist() + df_ld['SNP_B'].unique().tolist()))\n",
    "print('Number of SNPs pair-wise LD calculation: {}'.format(nr_snps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29035a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by phenotype and extract the rs column as a Series\n",
    "grouped = df_sig_primary.groupby('phenotype')['rs']\n",
    "\n",
    "# Create a dictionary comprehension that maps each phenotype to a list of rs values\n",
    "rs_dict = {phenotype: list(rs_values) for phenotype, rs_values in grouped}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3df553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pairwise LD results for each protein\n",
    "ld_primary = []\n",
    "for phenotype in df_sig_primary['phenotype'].unique():\n",
    "    pqtls = rs_dict[phenotype]\n",
    "    mask = df_ld['SNP_A'].isin(pqtls) & df_ld['SNP_B'].isin(pqtls)\n",
    "    df = df_ld.loc[mask].copy()\n",
    "    df['phenotype'] = phenotype\n",
    "    ld_primary.append(df)\n",
    "\n",
    "# Concatenate pairwise results from all proteins \n",
    "df_ld_postclump = pd.concat(ld_primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f6e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pairwise LD with r2 <=0.2\n",
    "le = df_ld_postclump[df_ld_postclump['R2']<=0.2]\n",
    "le_rate = pd.DataFrame(le.groupby('phenotype')['R2'].count()/df_ld_postclump.groupby('phenotype')['R2'].count())\n",
    "le_rate.columns=['%_R2<0.2']\n",
    "le_rate_mean = le_rate['%_R2<0.2'].mean()\n",
    "print('On average, {}% of pair-wise LD have a R2 <=0.2'.format(round(le_rate_mean, 2)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e8437",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "df_ld_postclump['R2'].hist(bins=50)\n",
    "plt.xlabel('LD (r2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16dc55d",
   "metadata": {},
   "source": [
    "#### Annotate primary pQTLs with VEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf02ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SNPs\n",
    "primary_pqtls = df_sig_primary['rs'].unique()\n",
    "primary_pqtls_vep = vep_output[vep_output['#Uploaded_variation'].isin(primary_pqtls)]\n",
    "consequences = primary_pqtls_vep[['#Uploaded_variation', 'Consequence']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536de2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary that matches SNPs and variant annotation\n",
    "dict_vep = {}\n",
    "for i, group in consequences.groupby('#Uploaded_variation'):\n",
    "    dict_vep[i] = group['Consequence'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8740a7",
   "metadata": {},
   "source": [
    "#### Extract missense variants to eliminate artefactual pQTLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd40465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many missense variants are in significant pQTLs before and after clumping\n",
    "missense_variants_all = vep_output.loc[vep_output['Consequence'] == 'missense_variant', '#Uploaded_variation']\n",
    "missense_variants_primary = consequences.loc[consequences['Consequence'] == 'missense_variant', '#Uploaded_variation']\n",
    "print(f\"{len(missense_variants_all)} missense variants in all significant pQTLs\")\n",
    "print(f\"{len(missense_variants_primary)} missense variants in primary pQTLs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8911b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and select relevant columns from vep_output\n",
    "coding_cons = vep_output.loc[vep_output['Consequence'] == 'missense_variant', ['#Uploaded_variation', 'SYMBOL', 'Protein_position', 'Amino_acids']].drop_duplicates()\n",
    "\n",
    "# Extract SNP to affected protein mapping\n",
    "IDmapping_snp_to_affectedprot = coding_cons[['#Uploaded_variation', 'SYMBOL']].drop_duplicates().set_index('#Uploaded_variation')['SYMBOL'].to_dict()\n",
    "\n",
    "# Map SNP IDs to affected proteins in df_sig\n",
    "df_sig_coding_cons = df_sig.assign(affected_protein=df_sig['rs'].map(IDmapping_snp_to_affectedprot))\n",
    "\n",
    "# Select only the rows where the affected protein matches the gene name\n",
    "df_sig_coding_tocheck = df_sig_coding_cons.loc[df_sig_coding_cons['Gene name'] == df_sig_coding_cons['affected_protein'], :].sort_values('phenotype')\n",
    "\n",
    "# Save file to path\n",
    "df_sig_coding_tocheck.to_csv(os.path.join(Base, 'analysis/alphamap/df_sig_coding_tocheck.csv'), index=False)\n",
    "\n",
    "# Extract coding consequences of all missense variants and save file to path\n",
    "coding_cons_allsig = coding_cons[coding_cons['#Uploaded_variation'].isin(df_sig_coding_tocheck['rs'].unique())]\n",
    "coding_cons_allsig.to_csv(os.path.join(Base,'analysis/alphamap/coding_cons_allsig.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c16628",
   "metadata": {},
   "source": [
    "#### Plot figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474bb737",
   "metadata": {},
   "source": [
    "##### Figure 4i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a212b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mycolorpy import colorlist as mcp\n",
    "\n",
    "# Compute values for the pie chart\n",
    "df_pie = consequences['Consequence'].value_counts() / consequences['#Uploaded_variation'].nunique()\n",
    "df_pie['others'] = df_pie[df_pie < 0.008].sum()\n",
    "toplot_pie = (df_pie[df_pie > 0.006] * 100).round().astype(int)\n",
    "\n",
    "# Generate labels for the pie chart\n",
    "labels = [f\"{index}: {value}%\" for index, value in toplot_pie.items()]\n",
    "\n",
    "# Generate colors for the pie chart\n",
    "colors = mcp.gen_color(cmap=\"Paired\", n=toplot_pie.shape[0])\n",
    "\n",
    "# Plot the pie chart\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(toplot_pie, colors=colors, wedgeprops={\"edgecolor\":\"black\", 'linewidth': 1, 'linestyle': 'solid', 'antialiased': True})\n",
    "ax.legend(labels, loc=(1, 0.1), labelcolor='black')\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "fig.savefig(os.path.join(figure_path, 'vep_pie.pdf'), dpi=120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f40785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of proteins per SNP and SNPs per protein\n",
    "protein_per_snp = df_sig_primary.groupby('rs')['Protein ID'].count().value_counts()\n",
    "snp_per_protein = df_sig_primary.groupby('Protein ID')['rs'].count().value_counts()\n",
    "\n",
    "# Compute the number of chromosomes per protein and identify the proteins with more than one chromosome\n",
    "chr_per_protein = df_sig_primary.groupby('Protein ID')['chr'].nunique()\n",
    "# Sort proteins by the number of chromosomes\n",
    "chr_per_protein = chr_per_protein.sort_values(ascending=False).to_frame(name='chr')\n",
    "proteins_with_multiple_chromosomes = chr_per_protein[chr_per_protein > 1].shape[0]\n",
    "\n",
    "# Prepare data for plotting\n",
    "snp_per_protein_plot = snp_per_protein[snp_per_protein.index.isin(range(1, 11))].sort_index()\n",
    "snp_per_protein_plot['>10'] = snp_per_protein[snp_per_protein.index > 10].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c60b31f",
   "metadata": {},
   "source": [
    "##### Figure 4f-g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35be4c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(6,3))\n",
    "\n",
    "# Plot number of associated proteins per SNP\n",
    "axs[0].bar(x=protein_per_snp.index, height=protein_per_snp, \n",
    "        facecolor='#53BBD5', edgecolor='#3B5488', width=0.6)\n",
    "axs[0].set_xticks(ticks=np.arange(1,7), labels=np.arange(1,7), rotation=45);\n",
    "axs[0].set_xlabel('Number of associated\\nproteins per SNP', fontsize=12)\n",
    "axs[0].set_ylabel('Number of pQTLs', fontsize=12)\n",
    "axs[1].bar(x=np.arange(11), height=snp_per_protein_plot, \n",
    "          facecolor='#53BBD5', edgecolor='#3B5488', width=0.6)\n",
    "\n",
    "# Plot number of associated SNPs per protein\n",
    "axs[1].set_xticks(ticks=np.arange(11), labels=[i for i in np.arange(1, 11)] + ['>10'], rotation=45);\n",
    "axs[1].set_xlabel('Number of associated\\n SNPs per protein', fontsize=12)\n",
    "axs[1].set_ylabel('Number of pQTLs', fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.35)\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.savefig(os.path.join(figure_path, 'protein_snp_frequency.pdf'), dpi=120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532eb53d",
   "metadata": {},
   "source": [
    "### cis/trans pQTLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db33c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mapping file from Protein ID to Transcription start site - refer to notebook TSS.ipynb\n",
    "df_mapping = pd.read_csv(os.path.join(Base, 'analysis/annotation/TSS_mapping_primary_pQTLs.csv'))\n",
    "\n",
    "# Add columns of protein coding location\n",
    "df_sig2 = df_sig_primary.merge(df_mapping, how='left', on='Protein ID').drop_duplicates()\n",
    "df_sig2 = df_sig2.assign(pqtl_id=df_sig2['rs']+df_sig2['phenotype']).set_index('pqtl_id')\n",
    "\n",
    "# Categorize cis and trans pQTLs \n",
    "from src.config import cis_trans_pqtl\n",
    "df_sig2_cistrans = cis_trans_pqtl(data=df_sig2, \n",
    "                                  chr_snp='chr', \n",
    "                                  pos_snp='ps', \n",
    "                                  chr_prot='chr_protein', \n",
    "                                  pos_protein ='Transcription start site (TSS)')\n",
    "\n",
    "df_sig2_cistrans['values'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8653bf",
   "metadata": {},
   "source": [
    "##### Fig. 4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78618604",
   "metadata": {},
   "outputs": [],
   "source": [
    "cis_trans_prop =df_sig2_cistrans['values'].value_counts(1, dropna=False).round(2)*100\n",
    "cis_trans_prop = cis_trans_prop.rename({'NaN':'Unmapped', 'cis':'Cis', 'trans':'Trans'})\n",
    "cis_trans_nr = df_sig2_cistrans['values'].value_counts(dropna=False)\n",
    "labels=[cis_trans_prop.index[i] +  \": {} ({}%)\".format(cis_trans_nr.iloc[i], int(cis_trans_prop.iloc[i])) for i in np.arange(cis_trans_prop.shape[0])]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2,2))\n",
    "colors=['white', '#53BBD5', 'gray']\n",
    "plt.pie(cis_trans_prop, colors=colors,\n",
    "        wedgeprops={\"edgecolor\":\"black\",'linewidth': 1, 'linestyle': 'solid', 'antialiased': True});\n",
    "plt.legend(labels, loc=(-0.2,-0.5), labelcolor='black', fontsize=12)\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.savefig(os.path.join(figure_path, 'cis_trans_pie.pdf'), dpi=120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e5ffc",
   "metadata": {},
   "source": [
    "#### how many proteins have cis, trans only and cis/trans associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3228c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cistranscount = df_sig2_cistrans.groupby(['phenotype'])['values'].value_counts().unstack().sort_values(by=['cis'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b507d0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "cis_only = cistranscount[cistranscount['cis'].notnull() & cistranscount['trans'].isnull()]\n",
    "trans_only = cistranscount[cistranscount['trans'].notnull() & cistranscount['cis'].isnull()]\n",
    "both = cistranscount[(cistranscount['cis'].notnull())&(cistranscount['trans'].notnull())]\n",
    "ctcount = pd.Series({'cis_only': len(cis_only), 'trans_only': len(trans_only), 'cis/trans': len(both)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbe5dee",
   "metadata": {},
   "source": [
    "##### Fig. 4e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2474ddf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(3,3))\n",
    "plots=plt.bar(x=ctcount.index, height=ctcount, width=0.4, facecolor='#53BBD5', edgecolor='#3B5488')\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.ylabel('Number of proteins', fontsize=12)\n",
    "for bar in plots.patches:\n",
    "    plt.annotate(bar.get_height(), xy=(bar.get_x() + bar.get_width()/2, bar.get_height()), \n",
    "                ha='center', va='center', xytext=(0, -9), textcoords='offset points',\n",
    "                 color='white', fontsize=12)\n",
    "plt.xticks(ticks=[0,1,2], labels=['Cis only', 'Trans only', 'Cis/Trans']);\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.savefig(os.path.join(figure_path, 'cis_trans_bar.pdf'), dpi=120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f381ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sig2_cistrans['-log10(p-wald)'] = [-np.log10(i) for i in df_sig2['p_wald']]\n",
    "df_sig2_cistrans['ind']=range(len(df_sig2_cistrans))\n",
    "df_sig2_cistrans = df_sig2_cistrans.sort_values(by='chr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36620caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sig3=df_sig2_cistrans.copy()\n",
    "df_sig3['rsID']=df_sig3['rs'].map(IDmapping_snp_to_rs)\n",
    "df_sig3=df_sig3.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f767ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dc412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_sig3.copy()\n",
    "df_plot.chr = df_plot.chr.astype('category')\n",
    "df_plot_grouped = df_plot.groupby('chr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0739be96",
   "metadata": {},
   "source": [
    "##### Fig. 4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14fe615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all primary pQTLs across the 22 chromosomes\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "sig_thres = -np.log10(5e-8)\n",
    "\n",
    "colors=['#3B5488','#53BBD5']\n",
    "x_labels = []\n",
    "x_labels_pos = []\n",
    "x_labels_end = []\n",
    "for num, (name, group) in enumerate(df_plot_grouped):\n",
    "    group.plot(kind='scatter', x='ind', y='-log10(p-wald)',color=colors[num % len(colors)], ax=ax, s=1, )\n",
    "    x_labels.append(name)\n",
    "    x_labels_pos.append((group['ind'].iloc[-1] - (group['ind'].iloc[-1] - group['ind'].iloc[0])/2))\n",
    "    x_labels_end.append(group['ind'].iloc[-1])\n",
    "major_tick_pos = [x_labels_pos[i] for i in [4, 9, 14, 19]]\n",
    "ax.set_xticks(major_tick_pos, labels=[5, 10, 15, 20], rotation=90);\n",
    "\n",
    "ax.set_xticks(x_labels_pos, minor=True)\n",
    "plt.axhline(y=sig_thres, color='gray', linestyle='--')\n",
    "ax.set_xlabel('pQTL position (Chromosome)', fontsize=14)\n",
    "plt.ylabel('$-log_{10}{(P)}$', fontsize=14)\n",
    "plt.grid(which='minor', ls =':');\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.savefig(os.path.join(figure_path, 'manhattan_sig_sizeclear.pdf'), dpi=120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70a57c1",
   "metadata": {},
   "source": [
    "##### Figure 4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51718d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,1))\n",
    "nr_bychr = df_plot_grouped.count()[['pqtl_id']]\n",
    "plt.bar(x=nr_bychr.index, height=nr_bychr['pqtl_id'], \n",
    "        facecolor='#53BBD5', edgecolor='#3B5488', width=0.6)\n",
    "plt.xticks(np.arange(1, 23), labels=[i for i in np.arange(1, 23)]);\n",
    "plt.ylabel('Number\\nof pQTLs', fontsize=12)\n",
    "plt.xlabel('Chromosome', fontsize=12)\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.savefig(os.path.join(figure_path, 'pqtls_by_chr.pdf'), dpi=120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26066664",
   "metadata": {},
   "source": [
    "##### Figure 4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56203382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toplot = df_sig3.copy().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636761ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read chromosome length\n",
    "df_chr_len = pd.read_csv(os.path.join(annotation_path, 'GRCh37_genome_length.txt'), sep='\\t', header=None, names=['chr', 'total_length_bp', 'Genbank_accession', 'Refseq_accession'])\n",
    "# Remove sex chromosomes\n",
    "df_chr_len = df_chr_len[~df_chr_len['chr'].isin(['X', 'Y'])].astype({'chr': int})\n",
    "\n",
    "cum_chr_length = np.cumsum(df_chr_len.set_index('chr')['total_length_bp'])\n",
    "cum_chr_length.loc[0] = 0\n",
    "\n",
    "xticks = [(cum_chr_length[i] - cum_chr_length[i - 1]) / 2 + cum_chr_length[i - 1] for i in range(1, 23)]\n",
    "\n",
    "major_ticks = [xticks[i] for i in [4, 9, 14, 19]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24c7283",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pos_snp = [cum_chr_length[i-1] for i in df_toplot['chr']] + df_toplot['ps'] \n",
    "new_pos_prot = [cum_chr_length[int(i)-1] for i in df_toplot['chr_protein']] + df_toplot['Transcription start site (TSS)'] \n",
    "df_toplot = df_toplot.assign(ps_snp = new_pos_snp, ps_prot = new_pos_prot )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4103271",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ax =sns.scatterplot(x='ps_snp', y='ps_prot', data=df_toplot, hue='values', \n",
    "                palette = {'cis':'red', 'trans':'#3B5488'}, s=8, legend=None)\n",
    "plt.xticks(major_ticks, labels=[5,10,15,20]);\n",
    "plt.yticks(major_ticks, labels=[5,10,15,20]);\n",
    "\n",
    "ax.set_xticks(xticks, major=True)\n",
    "ax.set_yticks(xticks, major=True)\n",
    "ax.set_xticks(cum_chr_length, minor=True)\n",
    "ax.set_yticks(cum_chr_length, minor=True)\n",
    "plt.xlabel('pQTL position', fontsize=14);\n",
    "plt.ylabel('Protein coding gene position', fontsize=14);\n",
    "plt.xlim(-1e8, cum_chr_length[22]+1e8)\n",
    "plt.ylim(-1e8, cum_chr_length[22]+1e8)\n",
    "plt.grid(which='minor', ls =':');\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.savefig(os.path.join(figure_path, 'cis_vs_trans.pdf'), dpi=120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4716f97",
   "metadata": {},
   "source": [
    "### Replication in ALD study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de66bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SNPs in the ALD study\n",
    "ald_vcf_path = '/home/projects/cpr_10006/people/lilniu/projects/proteogenomics/data/data_genotype/pqtl/data_genotype_subset/plink_qc2/'\n",
    "path_ald = ald_vcf_path + 'gemma/analysis/'\n",
    "bim_ald = ald_vcf_path + 'gemma/ald5.bim'\n",
    "snps_ald = pd.read_csv(bim_ald, header=None, sep='\\t', names=['chr', 'rs', 'what', 'pos', 'allele1', 'allele0'])\n",
    "snps_ald['rs'] = snps_ald['rs'].str.replace(':', \"_\")\n",
    "\n",
    "# Import proteins in the ALD study\n",
    "proteins_ald = pd.read_csv(os.path.join(crossref_path, 'ald/ald_protein.list'))\n",
    "\n",
    "# Check how many protein-SNP pairs can be tested in the ALD study\n",
    "cond1 = df_sig_primary['Protein ID'].isin(proteins_ald['Protein ID'].tolist())\n",
    "cond2 = df_sig_primary['rs'].isin(snps_ald['rs'])\n",
    "\n",
    "df_to_rep = df_sig_primary[cond1 & cond2]\n",
    "df_to_rep = df_to_rep.assign(pqtl_id=df_to_rep['rs'] + df_to_rep['Protein ID'], chr=df_to_rep['chr'].astype(str))\n",
    "df_to_rep.to_csv(os.path.join(path_ald, 'target_to_replicate.csv'), index=False)\n",
    "print('{} variant-protein pairs need to be tested'.format(df_to_rep.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f2ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_chr_to_rep = pd.DataFrame(df_to_rep.groupby('Protein ID')['chr'].unique())\n",
    "prot_chr_to_rep_dict = dict(zip(prot_chr_to_rep.index, prot_chr_to_rep['chr']))\n",
    "\n",
    "import pickle\n",
    "with open(os.path.join(path_ald, 'prot_chr_to_rep.pkl'), 'wb') as handle:\n",
    "    pickle.dump(prot_chr_to_rep_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b0e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Significant pQTLs in the replication cohort(p<0.05) and assign new columns\n",
    "df_sig_ald = pd.read_csv(os.path.join(crossref_path, 'ald/pqtl_ald_sig_nominal.csv'))\n",
    "df_sig_ald['Protein ID'] = df_sig_ald['phenotype'].str.split('_').str[0]\n",
    "df_sig_ald['pqtl_id'] = df_sig_ald['rs'] + df_sig_ald['Protein ID']\n",
    "df_sig_ald['chr'] = df_sig_ald['chr'].astype(str)\n",
    "df_sig_ald['maf'] = np.where(df_sig_ald['af'] < 0.5, df_sig_ald['af'].round(3), 0.5)\n",
    "df_sig_ald['-log10(p-wald)'] = (-np.log10(df_sig_ald['p_wald'])).round(3)\n",
    "df_sig_ald[['se_3digit', 'beta_3digit']] = df_sig_ald[['se', 'beta']].round(3)\n",
    "\n",
    "# significant pQTLs after Bonferroni correction\n",
    "# df_sig_ald = pd.read_csv(os.path.join(crossref_path, 'ald/pqtl_ald_sig.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13741cc",
   "metadata": {},
   "source": [
    "#### Replication\n",
    "- criteria: a pQTL is considered replicated if the SNP or its proxy in LD (+/1Mb, r2 > 0.2) is also sig. associated with the corresponding protein (p < 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1b3aa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.config import annotate_replication\n",
    "df_rep = annotate_replication(df_to_rep, df_sig_ald)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0252a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_replicated = df_rep[df_rep['replicated in ALD'].isin(['vicinity', 'exact'])].shape[0]\n",
    "per_replicated = no_replicated/df_rep.shape[0]*100\n",
    "print('{:.0f}% of testable primary pQTLs in the TARGET cohort was replicated in the ALD study.'.format(per_replicated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb61abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep.to_csv(os.path.join(crossref_path, 'ald/replicated_in_ald.csv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52730e44",
   "metadata": {},
   "source": [
    "#### Check correlation in beta statistics between discovery and replication cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a70bdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_exact = df_rep[df_rep['replicated in ALD']=='exact'][['pqtl_id', 'beta', 'rs', 'phenotype']].merge(df_sig_ald[['pqtl_id', 'beta']], \n",
    "                                                                        on='pqtl_id', how='left')\n",
    "df_exact=df_exact.rename({'beta_x':'beta_target', 'beta_y':'beta_ald'}, axis=1)\n",
    "df_exact['beta_target']=np.float64(df_exact['beta_target'])\n",
    "df_exact = df_exact.sort_values(by='beta_target')\n",
    "df_exact['pair_id']=np.arange(df_exact.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25fbe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep['replicated in ALD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d02873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exact_long = df_exact.melt(id_vars=['pqtl_id', 'pair_id'], value_name='beta', var_name='cohort')\n",
    "df_exact_long['cohort']=df_exact_long['cohort'].map({'beta_target':'Holbæk', 'beta_ald':'GALA-ALD'})\n",
    "df_exact[['beta_target', 'beta_ald']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12af0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "b = sns.scatterplot(x='beta_target', y='beta_ald', data=df_exact, edgecolor='darkblue', color='white')\n",
    "plt.xlim(-1.55, 1.55)\n",
    "plt.ylim(-1.55, 1.55);\n",
    "plt.xlabel('BETA (Holbæk)', fontsize=12)\n",
    "plt.ylabel('BETA (GALA-ALD)', fontsize=12)\n",
    "b.tick_params(labelsize=12)\n",
    "b.set_xticks([-1.5, -1.0, -0.5, 0, 0.5, 1, 1.5])\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "#plt.savefig(os.path.join(figure_path, 'beta_concordance_nominal.pdf'), dpi=120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf21eef0",
   "metadata": {},
   "source": [
    "##### Fig. 6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fbabe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "a = sns.scatterplot(x='pair_id', y='beta', hue='cohort', \n",
    "                data=df_exact_long, \n",
    "                    palette={'Holbæk':'darkblue', 'GALA-ALD':'darkred'},alpha=0.3, s=40)\n",
    "a.tick_params(labelsize=12)\n",
    "a.set_xlabel('')\n",
    "a.set_ylabel('BETA', fontsize=12)\n",
    "a.legend(prop={'size': 12})\n",
    "a.invert_yaxis()\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.savefig(os.path.join(figure_path, 'beta_concordance_dotplot_nominal.pdf'), dpi=120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93acae15",
   "metadata": {},
   "source": [
    "#### Prepare Supplementary Table 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21326ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table9 = df_rep.sort_values(by='replicated in ALD', ignore_index=True)\n",
    "df_table9[df_table9['replicated in ALD']=='exact'].to_csv(os.path.join(Base, 'analysis/dataset/dataset_replicated.csv'), index=False)\n",
    "df_table9['maf']=[i if i<=0.5 else 1-i for i in df_table9['af']]\n",
    "df_table9['-log10(p-wald)']=[-np.log10(i) for i in df_table9['p_wald']]\n",
    "\n",
    "cols_tokeep =['rs', 'chr', 'REF', 'ALT', 'Protein ID','Gene name', 'maf', 'beta', 'se', 'p_wald', \n",
    "             'replicated in ALD', 'evidence', 'maf_replication cohort', 'beta_replication cohort', \n",
    "             'se_replication cohort', 'p_wald_replication cohort', '-log10(p-wald)_replication cohort']\n",
    "df_table9=df_table9[cols_tokeep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff8db06",
   "metadata": {},
   "source": [
    "#### Export pQTLs for plotting dose-responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e680146",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (os.path.join(ald_vcf_path, 'exact_match_pqtl_id.txt'), 'w') as f:\n",
    "    for line in df_exact['rs'].tolist():\n",
    "        f.write(line.replace('_', ':') + '\\n')\n",
    "df_exact.to_csv(os.path.join(ald_vcf_path, 'exact_match_pqtl.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283443fb",
   "metadata": {},
   "source": [
    "### Cross reference other studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ce6407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import prior studies\n",
    "prior_studies=pd.read_csv(os.path.join(crossref_path, 'all_studies_tidy.txt'), low_memory=False)\n",
    "prior_studies.dropna(subset=['GeneSymbol', 'Chr.SNP.hg19', 'Pos.SNP.hg19'], inplace=True)\n",
    "prior_studies.reset_index(drop=True, inplace=True)\n",
    "prior_studies=prior_studies.astype({'Pos.SNP.hg19':int,\n",
    "                                   'Chr.SNP.hg19':str})\n",
    "\n",
    "# Save results\n",
    "prior_studies.to_csv(os.path.join(crossref_path, 'prior_studies_pqtl_list.txt'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540bea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import estimate_novelty, diff\n",
    "df_sig4 = estimate_novelty(df_sig3, prior_studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8413e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select novel significant genes\n",
    "df_sig4_novel = df_sig4[df_sig4['replicated in nr.studies'] == 0]\n",
    "\n",
    "# Identify unique genes\n",
    "unique_genes = sorted(set(df_sig4_novel['Gene name']) - set(prior_studies['GeneSymbol']))\n",
    "\n",
    "# Print summary\n",
    "print('{} new genes found compared to existing studies.'.format(len(unique_genes)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff96fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import itertools\n",
    "\n",
    "studies = [i for i in df_sig4['novel'] if i!='novel']\n",
    "study_occurences = []\n",
    "for i in studies:\n",
    "    res = ast.literal_eval(i)\n",
    "    study_occurences.append(res)\n",
    "\n",
    "study_occurences = list(itertools.chain(*study_occurences))\n",
    "study_occurences_df = pd.DataFrame({'occurences':study_occurences})['occurences'].value_counts()/1116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72498fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of studies in which each gene is replicated\n",
    "replication_matrix = df_sig4['replicated in nr.studies'].value_counts().sort_index()\n",
    "\n",
    "replication_matrix_toplot = replication_matrix[replication_matrix.index<11]\n",
    "replication_matrix_toplot['>10'] = replication_matrix[replication_matrix.index>10].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc4104f",
   "metadata": {},
   "source": [
    "##### Fig. S4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea30681",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(figsize=(4,3))\n",
    "plt.bar(x=np.arange(replication_matrix_toplot.__len__()), \n",
    "        height=replication_matrix_toplot, width=0.6)\n",
    "plt.xticks(np.arange(replication_matrix_toplot.__len__()), \n",
    "           labels=replication_matrix_toplot.index, \n",
    "          rotation=30);\n",
    "plt.ylabel('Number of pQTLs', fontsize=14)\n",
    "plt.xlabel('Number of studies', fontsize=14)\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.savefig(os.path.join(figure_path, 'replication_matrix.pdf'), dpi=120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3443cfb",
   "metadata": {},
   "source": [
    "#### Write to results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b67cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_path ='/home/projects/cpr_10006/people/lilniu/projects/target/data/data_genotype/subset/Formatted/plink_qc4'\n",
    "with open (os.path.join(vcf_path, 'novel_pqtl_id.txt'), 'w') as f:\n",
    "    for line in df_sig4_novel['rs'].tolist():\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "df_sig4_novel.to_csv(os.path.join(vcf_path, 'novel_pqtl.csv'), index=False)\n",
    "\n",
    "with open (os.path.join(vcf_path, 'primary_pqtl_id.txt'), 'w') as f:\n",
    "    for line in df_sig2['rs'].tolist():\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "df_sig4.to_csv(os.path.join(vcf_path, 'primary_pqtl.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8bd3ff",
   "metadata": {},
   "source": [
    "#### How many of the novel pQTLs were replicated in ALD? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d900b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pQTLs replicated in the replication cohort\n",
    "df_replicated_ald = df_rep[df_rep['replicated in ALD']!='no']\n",
    "\n",
    "# Extract the relevant columns from df_replicated_ald and df_sig4_novel\n",
    "replicated_ids = df_replicated_ald['rs']+df_replicated_ald['Protein ID']\n",
    "novel_ids = df_sig4_novel['rs']+df_sig4_novel['Protein ID']\n",
    "\n",
    "# Compute the intersection of the two sets and count the number of elements\n",
    "num_common_ids = len(intersection(replicated_ids, novel_ids))\n",
    "\n",
    "# Print the result\n",
    "print('The number of common IDs between the two datasets is: {}'.format(num_common_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6c3e2e",
   "metadata": {},
   "source": [
    "#### Prepare Supplementary Table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2574481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table5 = df_sig4.copy()\n",
    "df_table5 = df_table5.reset_index().drop(['index', 'ind'], axis=1)\n",
    "df_table5['study-wide significant']=np.where(df_table5['p_wald']<5e-8/420, 'yes', 'no')\n",
    "df_table5['variant annotation'] = df_table5['rs'].map(dict_vep)\n",
    "df_table5['novel'] = df_table5['novel'].replace('[]', 'novel')\n",
    "\n",
    "cols_tokeep = ['pqtl_id', 'rs', 'rsID',  'chr', 'ps', 'variant annotation', 'REF', 'ALT', 'maf', \n",
    "               'p_wald', '-log10(p-wald)', 'beta', 'se', 'study-wide significant', \n",
    "              'values', 'Protein ID', 'Gene name', 'UniParc ID','chr_protein',\n",
    "              'Gene start (bp)', 'Gene end (bp)', 'Transcription start site (TSS)', \n",
    "               'novel', 'replicated in nr.studies']\n",
    "\n",
    "new_names = ['pQTL_ID', 'SNP', 'rsID', 'chr', 'pos', 'VEP annotation','reference_allele', 'alternative_allele', \n",
    "            'MAF', 'p_wald', '-log10(p-wald)', 'beta', 'standard error', 'study-wide significant', \n",
    "            'cis/trans', 'Protein ID', 'Gene name', 'UniParc ID','chr_protein', 'Gene start (bp)', \n",
    "             'Gene end (bp)', 'Transcription start site (TSS)', 'novel', 'replicated in nr.studies']\n",
    "\n",
    "df_table5_formatted = df_table5[cols_tokeep].rename(dict(zip(cols_tokeep, new_names)), axis=1)\n",
    "df_table5_formatted['artefactual pQTLs'] = np.where(df_table5_formatted['Protein ID']=='A0A0D9SG88', 'yes', 'no')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fe76b1",
   "metadata": {},
   "source": [
    "### Mapping pQTLs to GWAS Catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5114126",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas_catal = pd.read_csv(os.path.join(crossref_path, 'gwas_catalog_v1.0.2-associations_e107_r2022-07-30.tsv'), \n",
    "                         sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d65842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all mapped GWAS traits for inspection\n",
    "with open(os.path.join(crossref_path, 'gwas_traits'), 'w') as file:\n",
    "    for i in gwas_catal['MAPPED_TRAIT'].unique():\n",
    "        file.write(str(i)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1420f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import annotate_with_gwas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962216b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sig4_gwas = annotate_with_gwas(df_sig4, gwas_catal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449c09db",
   "metadata": {},
   "source": [
    "#### Prepare Supplementary Table 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc69ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_tokeep = ['pqtl_id', 'rsID', 'Protein ID', 'Gene name','Nr. GWAS_records','replicated in nr.studies',\n",
    "                'GWAS_traits', 'Nr. GWAS_traits', 'Study accessions', 'Mapped trait urls']\n",
    "\n",
    "df_table8 = df_sig4_gwas[cols_tokeep]\n",
    "df_table8 = df_table8[df_table8['Nr. GWAS_traits']>0].rename({'pqtl_id':'pQTL_ID'}, axis=1)\n",
    "df_table8['novel pQTL'] = np.where(df_table8['replicated in nr.studies']>0, 'no', 'yes')\n",
    "df_table8=df_table8.drop(['replicated in nr.studies'], axis=1).sort_values(by='Nr. GWAS_traits', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5a476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write table 5,8,9 to supplementary tables\n",
    "with pd.ExcelWriter(os.path.join(Base,'analysis/tables/TableS589.xlsx')) as writer:\n",
    "    df_table5_formatted.to_excel(writer,sheet_name='ST5', index=False)\n",
    "    df_table8.to_excel(writer, sheet_name='ST8', index=False)\n",
    "    df_table9.to_excel(writer, sheet_name='ST9', index=False)\n",
    "    \n",
    "df_table5_formatted.to_csv(os.path.join(Base, 'analysis/tables/TableS5.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51561e3",
   "metadata": {},
   "source": [
    "#### Plot regional association plots between GWAS traits loci and pQTLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b902cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDmapping_proteinID_to_phenotype = {key:value for (value,key) in zip(IDmapping_phenotype_to_proteinID.keys(), IDmapping_phenotype_to_proteinID.values())}\n",
    "IDmapping_pqtlid_to_cistrans = dict(zip(df_sig2_cistrans.index, df_sig2_cistrans['values']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579d6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_thres_gwas= 5e-8\n",
    "sig_thres_study= 1.2e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7247082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regional_association(rsid, proteinid, ax, figureid):\n",
    "    phenotype = IDmapping_proteinID_to_phenotype[proteinid]\n",
    "    markers = {\"yes\": \"v\", \"no\": \"o\"}\n",
    "    #annotation df\n",
    "    df = pd.read_csv(os.path.join(result_path, \"assoc/{}.assoc.txt\".format(phenotype)), sep='\\t')\n",
    "    df['rsID']=df['rs'].map(IDmapping_snp_to_rs)\n",
    "    chr_pos = df[df['rsID']==rsid].iloc[0]['chr']\n",
    "    snp_pos = df[df['rsID']==rsid].iloc[0]['ps']\n",
    "    df = df[(df['chr']==chr_pos) & (df['ps'] > snp_pos-5e5) & (df['ps'] < snp_pos+5e5)]\n",
    "    df['phenotype']=proteinid\n",
    "    df['-log10(p-wald)'] = -np.log10(df.p_wald)\n",
    "    df['Gene name']=df['phenotype'].str.split('_').str[1]\n",
    "    df['pqtl_id']=df['rs']+df['phenotype']\n",
    "    df['cis_trans']=df['pqtl_id'].map(IDmapping_pqtlid_to_cistrans)\n",
    "    df['target_qtl']='no'\n",
    "    df.loc[df['rsID']==rsid, 'target_qtl']='yes'\n",
    "\n",
    "    #plot\n",
    "    ax.text(-0.2, 1.05, figureid, size=12, weight='bold',transform=ax.transAxes )\n",
    "    sns.scatterplot(x='ps', y='-log10(p-wald)', data=df, \n",
    "                    legend=False, s=6,edgecolor='darkblue', \n",
    "                    style='target_qtl', color='darkblue', hue='target_qtl', ax=ax)\n",
    "    ax.axhline(y=-np.log10(sig_thres_gwas), color='gray', linestyle='--', lw=1)\n",
    "    ax.axhline(y=-np.log10(sig_thres_study), color='darkred', linestyle='--', lw=1)\n",
    "    ax.set_xlabel('Position on Chromosome {}'.format(chr_pos))\n",
    "    ax.set_ylabel('$-log_{10}{(P)}$')\n",
    "    pqtl_info = df[df['ps']==snp_pos]\n",
    "    if pqtl_info.shape[0]==0:\n",
    "        print('No target info found')\n",
    "    else:\n",
    "        text = '{} ({})'.format(pqtl_info.iloc[0]['Gene name'], pqtl_info.iloc[0]['cis_trans'])\n",
    "        ax.annotate(text, (0.02, 0.9), xycoords='axes fraction')\n",
    "        ax.annotate(rsid, (snp_pos+1e4, pqtl_info.iloc[0]['-log10(p-wald)']))\n",
    "        ax.set_ylim(-0.1,df['-log10(p-wald)'].max()*1.3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acd7ef1",
   "metadata": {},
   "source": [
    "##### Fig. 5i-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7acf1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,1,figsize=(3,8))\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.3)\n",
    "plot_regional_association(rsid='rs173539', proteinid='P02647_APOA1', ax=axs[0], figureid='i')\n",
    "plot_regional_association(rsid='rs73001065', proteinid='P04114_APOB', ax=axs[1], figureid='k')\n",
    "plot_regional_association(rsid='rs6762719', proteinid='E7EQB2_LTF', ax=axs[2], figureid='j')\n",
    "\n",
    "# Save figure\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "fig.savefig(os.path.join(figure_path, 'regional_associations.pdf'), dpi=120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f287b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3c3240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
