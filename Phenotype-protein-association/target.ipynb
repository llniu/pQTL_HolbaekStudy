{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from src.imputation import imputation_normal_distribution, log2, NP_LOG_FCT, IMPUTATION_MEAN_SHIFT, IMPUTATION_STD_SHRINKAGE\n",
    "from src.correlation import pairwise_correlation\n",
    "import pingouin as pg\n",
    "from matplotlib_venn import venn3, venn3_circles\n",
    "from venn import venn\n",
    "import statsmodels.stats.multitest as multi\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import zscore\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Proteomics data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Define directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the number of available CPUs\n",
    "CPUS = os.cpu_count()\n",
    "\n",
    "# Define the paths for the raw and processed data folders\n",
    "DATA_FOLDER_RAW = 'data/raw'\n",
    "DATA_FOLDER_PROCESSED = 'data/processed'\n",
    "DATA_FOLDER_CLINIC = '/Volumes/auditgroupdirs/SUND-CBMR-Childhood-Genetic-TCOC/Proteomics analysis/GitHub/TARGET/'\n",
    "\n",
    "# Create the processed data folder if it doesn't exist\n",
    "os.makedirs(DATA_FOLDER_PROCESSED, exist_ok=True)\n",
    "\n",
    "# Define the paths for the table, result, and figure folders\n",
    "TABLE_FOLDER = 'tables'\n",
    "RESULT_FOLDER = 'results'\n",
    "FIGURE_FOLDER = Path('figures')\n",
    "FIGURE_FOLDER.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data and format column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read annotation file\n",
    "annotation_file = pd.read_csv(os.path.join(DATA_FOLDER_RAW, 'Experiment annotation file.csv'), index_col = [0])\n",
    "\n",
    "# Read Spectronaut output report into a DataFrame\n",
    "report_filename = 'Protein_20210924_230719_TARGET_SNv15.4_Report.csv'\n",
    "report_plasma = pd.read_csv(os.path.join(DATA_FOLDER_RAW, report_filename), na_values='Filtered')\n",
    "\n",
    "# Drop columns that are not needed\n",
    "report_plasma.drop(['PG.Qvalue', 'PG.MolecularWeight', 'PG.ProteinDescriptions'], axis=1, inplace=True)\n",
    "\n",
    "# Rename columns to have more descriptive names\n",
    "report_plasma.rename({'PG.Genes': 'Gene names', 'PG.ProteinAccessions': 'Protein IDs'}, inplace= True, axis=1)\n",
    "report_plasma = report_plasma.set_index(['Protein IDs', 'Gene names'])\n",
    "\n",
    "# Modify the column names to remove unnecessary information\n",
    "report_plasma.rename(columns=lambda c: c.split(' ')[1].replace('.PG.Quantity', ''), inplace=True)\n",
    "\n",
    "# Rename columns to match the annotation file\n",
    "#report_plasma.rename({'ID':'Protein ID', 'names':'Gene name'}, inplace=True, axis=1)\n",
    "\n",
    "# Rename the columns with the sample IDs\n",
    "sample_id_mapping = dict(zip(annotation_file.index, annotation_file['Sample ID']))\n",
    "report_plasma.rename(sample_id_mapping, inplace=True, axis=1)\n",
    "report_plasma = report_plasma.reset_index()\n",
    "\n",
    "# Preview the first few rows of the DataFrame\n",
    "report_plasma.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the leading protein ID and gene name\n",
    "report_plasma['Protein ID'] = report_plasma['Protein IDs'].str.split(';').str[0]\n",
    "report_plasma['Gene name'] = report_plasma['Gene names'].astype(str).str.split(';').str[0]\n",
    "\n",
    "IDmapping_proteinid_to_proteinids = dict(zip(report_plasma['Protein ID'], report_plasma['Protein IDs']))\n",
    "IDmapping_genename_to_genenames = dict(zip(report_plasma['Gene name'], report_plasma['Gene names']))\n",
    "report_plasma.drop(['Protein IDs', 'Gene names'], axis=1, inplace=True)\n",
    "\n",
    "# Drop contaminants and set the index to the Protein ID column\n",
    "contaminant_ids = report_plasma[report_plasma['Protein ID'].str.startswith('CON')]['Protein ID']\n",
    "data_plasma_raw = report_plasma[~report_plasma['Protein ID'].isin(contaminant_ids)].set_index('Protein ID')\n",
    "\n",
    "# Create a dictionary to map Protein ID to Gene name and batch\n",
    "IDmapping_proteinid_to_genename = data_plasma_raw['Gene name'].to_dict()\n",
    "IDmapping_sampleID_to_Batch = dict(zip(annotation_file['Sample ID'], annotation_file['Grouping_batch']))\n",
    "\n",
    "# Drop the Gene name column from the DataFrame\n",
    "data_plasma_raw.drop('Gene name', axis=1, inplace=True)\n",
    "\n",
    "# Get the sample IDs to use for the analysis\n",
    "non_qa_samples = annotation_file[annotation_file['Grouping_plate'] != 'QA']\n",
    "sample_ids = non_qa_samples['Sample ID'].tolist()\n",
    "\n",
    "# Combine Protein ID and Gene name into a single index\n",
    "data_plasma_raw.index = [str(i) + '_' + str(IDmapping_proteinid_to_genename[i]) for i in data_plasma_raw.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Filter data based on data completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the completeness threshold for filtering\n",
    "DATA_COMPLETENESS = 0.4\n",
    "data_plasma_filtered = data_plasma_raw.dropna(axis=0, thresh = data_plasma_raw.shape[1] * DATA_COMPLETENESS)\n",
    "data_plasma_filtered_log = data_plasma_filtered.apply(log2)\n",
    "proteins = data_plasma_filtered.T.columns.tolist()\n",
    "\n",
    "# Calculate the percent of missing values in the filtered data\n",
    "missing_value_percent = data_plasma_filtered.isna().mean().mean()\n",
    "missing_value_pct_perprotein = data_plasma_filtered.isnull().sum(axis=1)/data_plasma_filtered.shape[1]\n",
    "print(f'Missing data after filtering: {missing_value_percent:.2%}')\n",
    "\n",
    "# Print the shape of the filtered data\n",
    "print(f'Filtered data shape: {data_plasma_filtered.shape}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Check if there is batch effect by PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "X_train = data_plasma_filtered_log.T.dropna(axis=1)\n",
    "X_scaled = preprocessing.StandardScaler().fit_transform(X_train)\n",
    "X=X_scaled\n",
    "pca = PCA(n_components=10, random_state=2021)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "X_df = pd.DataFrame(data=X_pca, columns=['PC{}'.format(i) for i in range(1, 11)])\n",
    "\n",
    "# Loadings\n",
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "df_loadings = pd.DataFrame(loadings, columns=['PC{}'.format(i) for i in range(1, 11)], index=X_train.columns)\n",
    "df_loadings['Gene name'] = df_loadings.index.map(IDmapping_proteinid_to_genename)\n",
    "df_loadings['missing_value_pct']=pd.Series(missing_value_pct_perprotein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(pca.explained_variance_ratio_[0]*100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate PCA plot\n",
    "color_batches = [IDmapping_sampleID_to_Batch[i] for i in X_train.index]\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=color_batches, s=10, palette='Paired', alpha=0.8)\n",
    "plt.title('Principal component plot', fontsize=20)\n",
    "plt.xlabel('principal component 1 ({}%)'.format(round(pca.explained_variance_ratio_[0]*100, 1)), fontsize=16)\n",
    "plt.ylabel('principal component 2 ({}%)'.format(round(pca.explained_variance_ratio_[1]*100, 1)), fontsize=16)\n",
    "plt.xticks(fontsize=16);\n",
    "plt.yticks(fontsize=16);\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.savefig(os.path.join(FIGURE_FOLDER, 'PCA_batches.pdf'), bbox_inches='tight', dpi=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_DATA = False\n",
    "if SCALE_DATA:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    data_plasma_filtered_log_imputed_np = scaler.fit_transform(data_plasma_filtered_log.values)\n",
    "    data_plasma_filtered_log_imputed = data_plasma_filtered_log.copy()\n",
    "    data_plasma_filtered_log_imputed.loc[:,:] = np.nan_to_num(data_plasma_filtered_log_imputed_np)\n",
    "else:\n",
    "    data_plasma_filtered_log_imputed = data_plasma_filtered_log.apply(imputation_normal_distribution)\n",
    "    assert data_plasma_filtered_log_imputed.loc['Q9Y6Z7_COLEC10', 'Plate1_2'] - 9.370928 < 0.00001, 'Imputed value changed in comparison to previous run'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from combat.pycombat import pycombat\n",
    "dm = data_plasma_filtered_log_imputed[sample_ids].copy()\n",
    "batch = [IDmapping_sampleID_to_Batch[i] for i in dm.columns]\n",
    "data_plasma_filtered_log_imputed_corrected = pycombat(dm, batch)\n",
    "assert data_plasma_filtered_log_imputed_corrected.loc['Q9Y6Z7_COLEC10', 'Plate1_2'] - 9.761459 < 0.00001, 'Corrected value changed in comparison to previous run'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_RESULTS = 'data/processed/proteomics_datasets.xlsx'\n",
    "\n",
    "def format_dataset(df):\n",
    "    df_new=df.copy()\n",
    "    df_new.rename_axis('ProteinID_Genename', axis=0, inplace=True)\n",
    "    df_new['Protein ID'] = df_new.index.str.split('_').str[0]\n",
    "    df_new['Gene name'] = df_new.index.str.split('_').str[1]\n",
    "    df_new['Protein IDs'] = df_new['Protein ID'].map(IDmapping_proteinid_to_proteinids)\n",
    "    df_new['Gene names'] = df_new['Gene name'].map(IDmapping_genename_to_genenames)\n",
    "    return df_new\n",
    "\n",
    "# with pd.ExcelWriter(FILE_RESULTS) as writer:\n",
    "#     format_dataset(data_plasma_raw).to_excel(writer, sheet_name='raw')\n",
    "#     format_dataset(data_plasma_filtered_log).to_excel(writer, sheet_name='filtered_log2')\n",
    "#     format_dataset(data_plasma_filtered_log_imputed).to_excel(writer, sheet_name='filtered_log2_imputed')\n",
    "#     format_dataset(data_plasma_filtered_log_imputed_corrected).to_excel(writer, sheet_name='imputed_batchcorrected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Quality assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate CV based on 94 quality assessment samples (pooled plasma allocated in 24 plates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_plasma = annotation_file[annotation_file['Grouping_batch'] == 'QA']['Sample ID'].tolist()\n",
    "df_qa = data_plasma_filtered.copy()[qa_plasma]\n",
    "coef_of_variation = lambda x: np.std(x) / np.mean(x)\n",
    "proteins_cv = df_qa.apply(coef_of_variation, axis =1)\n",
    "proteins_log2_abundance = np.log2(df_qa.median(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('median cv: {}'.format(round(proteins_cv.median(),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv = pd.DataFrame({'Coefficient of variation':proteins_cv, \n",
    "                      'Protein abundance [Log2]':proteins_log2_abundance}).sort_values(by='Coefficient of variation')\n",
    "df_cv['color']=np.where(df_cv['Coefficient of variation']<0.3, 'CV<30%', 'rest')\n",
    "df_cv.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate figures of data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_dep_wide = pd.DataFrame({'raw': data_plasma_raw.count(), 'filtered':data_plasma_filtered.count()})\n",
    "prot_dep = pd.melt(prot_dep_wide, var_name='dataset', value_name='Number of proteins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv['Protein abundance [Log10]'] = np.log10(2**df_cv['Protein abundance [Log2]'])\n",
    "df_cv = df_cv.sort_values(by='Protein abundance [Log2]', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv['rank']=np.arange(df_cv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_dep.groupby('dataset')['Number of proteins'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supplementary figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12,4))\n",
    "sns.boxplot(data = prot_dep, x='dataset', y='Number of proteins', color='white', ax=ax1)\n",
    "ax1.set_ylim(0, 520)\n",
    "for i,box in enumerate(ax1.artists):\n",
    "    box.set_edgecolor('black')\n",
    "    box.set_facecolor('white')\n",
    "\n",
    "    # iterate over whiskers and median lines\n",
    "    for j in range(6*i,6*(i+1)):\n",
    "         ax1.lines[j].set_color('black')\n",
    "ax2 = sns.scatterplot(x=df_cv['rank'], y=df_cv['Protein abundance [Log10]'], ax=ax2)\n",
    "ax3 = sns.scatterplot(x=df_cv['Protein abundance [Log2]'], y=df_cv['Coefficient of variation'], hue=df_cv['color'], ax=ax3)\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.savefig('figures/data_quality.pdf', dpi=120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Double key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the double ID file into a DataFrame and set the index\n",
    "double_id_file = pd.read_csv(os.path.join(DATA_FOLDER_RAW, 'Target_sampleID.csv'), index_col='blood_sample_ID').dropna(how='all')\n",
    "\n",
    "# Drop rows with all missing values\n",
    "double_id_file = double_id_file.dropna(how='all')\n",
    "\n",
    "# Create a dictionary to map blood sample IDs to proteomics sample IDs and vice versa\n",
    "IDmapping_bloodSampleID_to_SampleID = double_id_file['Sample ID'].to_dict()\n",
    "IDmapping_SampleID_to_bloodSampleID = dict(zip(double_id_file['Sample ID'], double_id_file.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the output file\n",
    "output_file_path = os.path.join('pQTL', 'phenomics', 'IDmapping_SampleID_to_bloodSampleID.p')\n",
    "\n",
    "# Dump the dictionary to the output file\n",
    "with open(output_file_path, 'wb') as output_file:\n",
    "    pickle.dump(IDmapping_SampleID_to_bloodSampleID, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Clinical data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data and add relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the raw clinical data file\n",
    "data_cli_raw = pd.read_csv(os.path.join(DATA_FOLDER_CLINIC, 'HOL_dataset_massspec_bas_fu_clean_v2022.07.07.csv'), \n",
    "                          sep=';', decimal=',', low_memory=False)\n",
    "\n",
    "# Drop unnecessary columns and rows with all missing values\n",
    "data_cli_raw.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "data_cli_raw.dropna(how='all', axis=1, inplace=True)\n",
    "\n",
    "# Rename columns and add a proteomics analysis date column\n",
    "data_cli_raw.rename({'gender':'sex'}, axis=1, inplace=True)\n",
    "data_cli_raw['proteomics_analysis_date'] = pd.Timestamp('2021-07-17')\n",
    "\n",
    "# Assign groups of overweight and normalweight \n",
    "data_cli_raw['obesity'] = np.where(data_cli_raw['z_BMI.Nysom']>=1.28, 1, 0)\n",
    "\n",
    "# Add a column for the time between blood sample collection and analysis\n",
    "#data_cli_raw['blood_sample_date_ts']=[pd.Timestamp(s) for s in data_cli_raw['blood_sample_date']]\n",
    "data_cli_raw['blood_sample_date_ts'] = pd.to_datetime(data_cli_raw['blood_sample_date'])\n",
    "storagetime = data_cli_raw['proteomics_analysis_date'] - data_cli_raw['blood_sample_date_ts']\n",
    "data_cli_raw['time_to_analysis'] = storagetime.dt.days\n",
    "\n",
    "# Drop any duplicated rows and save the filtered DataFrame to a variable\n",
    "data_cli_filtered = data_cli_raw[~data_cli_raw.index.duplicated(keep=False)]\n",
    "\n",
    "print('Filtered clinical data shape: {}'.format(data_cli_filtered.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract clinical data for samples with proteomics measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cli_prot = pd.DataFrame(data= data_plasma_raw.T.index, columns=['Sample ID']).set_index('Sample ID')\n",
    "data_cli_prot['blood_sample_ID'] = data_cli_prot.index.map(IDmapping_SampleID_to_bloodSampleID)\n",
    "data_cli_prot = data_cli_prot.reset_index().merge(data_cli_filtered, how='left', left_on='blood_sample_ID', \n",
    "                                                  right_on='biobank_ID').set_index('Sample ID')\n",
    "data_cli_prot.drop('blood_sample_ID', axis=1, inplace=True)\n",
    "\n",
    "data_cli_prot['age_int']=data_cli_prot['age'].round(0)\n",
    "bin_numbers_bmi = pd.qcut(\n",
    "    x=data_cli_prot['BMI'], q=20, labels=False, duplicates='drop'\n",
    ")\n",
    "data_cli_prot['bin_numbers_bmi'] = bin_numbers_bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [i for i in data_cli_prot['visit_date'] if type(i)==str]\n",
    "dates_year = [int(i.split('-')[0]) for i in dates]\n",
    "data_cli_prot['visit_date_year'] = data_cli_prot['visit_date'].map(dict(zip(dates, dates_year)))\n",
    "data_cli_prot['visit_date_year_binary'] = np.where(data_cli_prot['visit_date_year']>2015, '>2015', 'â‰¤2015')\n",
    "\n",
    "df = data_cli_prot.copy()\n",
    "df['mr_liverfat_above5%'] = np.where(df['mr_real_liverfat_percent']>5, 1, 0)\n",
    "df['mr_liverfat_above1.5%'] = np.where(df['mr_real_liverfat_percent']>1.5, 1, 0)\n",
    "df.loc[df['mr_real_liverfat_percent'].isnull(), 'mr_liverfat_above5%'] = np.nan\n",
    "df.loc[df['mr_real_liverfat_percent'].isnull(), 'mr_liverfat_above1.5%'] = np.nan\n",
    "\n",
    "prot_batch = pd.get_dummies(annotation_file.set_index('Sample ID')['Grouping_batch'])\n",
    "prot_batches = prot_batch.columns.tolist()\n",
    "df = df.join(prot_batch)\n",
    "data_cli_prot = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clinical data for phenomics analysis \n",
    "data_cli_prot.reset_index().to_csv('pQTL/phenomics/data_cli_prot.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Export data for Dash app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dash = data_plasma_filtered_log.T.join(data_cli_prot).rename_axis('Sample ID', axis=0)[proteins + ['age_int', 'sex', 'z_BMI.Nysom']]\n",
    "data_dash.to_csv('dash/dataset/data_age_sex.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline participant characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cli_base = data_cli_prot.copy()\n",
    "data_cli_base = data_cli_base[data_cli_base['QA']==0]\n",
    "\n",
    "para_toinclude = ['age_year', 'sex', 'z_BMI.Nysom','BMI','height', 'weight', \n",
    "                  'tanner_stage', 'pubertal_status2', 'triglycerides', \n",
    "                  'chol_total', 'chol_ldl', 'chol_hdl',\n",
    "                  'glucose', 'insulin', 'HbA1c', 'ALAT', 'ASAT', 'GGT', 'obesity']\n",
    "\n",
    "data_cli_base = data_cli_base[para_toinclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cli_base.groupby('obesity')['pubertal_status2'].value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cli_base.groupby('obesity').quantile(0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Combine proteomics and clinical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined = data_plasma_filtered_log_imputed_corrected.T.join(data_cli_prot).rename_axis('Sample ID', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check sample quality markers by sample collection time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_markers=pd.read_csv('data/processed/quality_markers.csv')['denoise_proteins']\n",
    "REPLOT_FIGURES = False\n",
    "if REPLOT_FIGURES:\n",
    "    for i in quality_markers.tolist():\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.boxplot(x='visit_date_year', y=i, data=data_combined, color='crimson', )\n",
    "        plt.title(i, fontsize=16)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.savefig('figures/quality_markers/{}'.format(i), bbox_inches='tight', dpi=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normality test before transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long data format to ease computation \n",
    "data_long = data_combined[proteins].melt(var_name='ProteinID_Genename', value_name='MS signal [Log2]').set_index('ProteinID_Genename')\n",
    "\n",
    "from src.statistical_testing import normality_pg\n",
    "# Set a dummy variable needed for pingouin.normality\n",
    "data_long['group_dummy']=1\n",
    "normality_results = normality_pg(data=data_long, dv='MS signal [Log2]', group='group_dummy')\n",
    "\n",
    "# Show results\n",
    "print('Number of protein with non-normal distribution:{}'.format(normality_results['normal'].value_counts()[False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranked-based inverse normalized transformation (INT)\n",
    "- https://stackoverflow.com/questions/15549836/transform-data-to-fit-normal-distribution\n",
    "- [good discussion on violating OLS residual normality assumption](https://stats.stackexchange.com/questions/29731/regression-when-the-ols-residuals-are-not-normally-distributed)\n",
    "- [good discussion on testing non-linear association](https://stats.stackexchange.com/questions/35893/how-do-i-test-a-nonlinear-association)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform ranked-based inverse normalized transformation (INT) on protein levels per protein\n",
    "# Refer to https://github.com/edm1/rank-based-INT\n",
    "\n",
    "from src.rank_based_int import rank_INT\n",
    "RE_INT = False\n",
    "\n",
    "if not RE_INT:\n",
    "    data_proteomics_int = pd.read_csv('data/processed/proteomics_filtered_imputed_corrected_int.csv').set_index('Sample ID')\n",
    "else:\n",
    "    new_df = []\n",
    "    for protein in tqdm(proteins):\n",
    "        new_df.append(pd.DataFrame(rank_INT(data_plasma_filtered_log_imputed_corrected.T[protein], stochastic=False), columns=[protein]))\n",
    "    data_proteomics_int = pd.concat(new_df, axis=1)\n",
    "    data_proteomics_int.rename_axis('Sample ID', axis=0, inplace=True)\n",
    "    data_proteomics_int.to_csv('data/processed/proteomics_filtered_imputed_corrected_int.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data_proteomics_int.loc['Plate1_2', 'Q9Y6Z7_COLEC10'] - -1.055522 < 0.00001, 'Normalized value changed in comparison to previous run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined_int = data_proteomics_int.join(data_cli_prot).rename_axis('Sample ID', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate normality test after data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = ['sex', 'z_BMI.Nysom' , 'age', 'time_to_analysis', 'pubertal_status2', ]\n",
    "lr_residuals = {}\n",
    "for protein in tqdm(proteins):\n",
    "    lr = pg.linear_regression(X=data_combined_int[covariates], y=data_combined_int[protein], remove_na=True)\n",
    "    residuals = lr.residuals_    \n",
    "    lr_residuals[protein]=residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normality_test_residuals = []\n",
    "for protein in lr_residuals.keys():\n",
    "    normal = pg.normality(lr_residuals[protein])\n",
    "    normal['protein']=protein\n",
    "    normality_test_residuals.append(normal)\n",
    "pd.concat(normality_test_residuals)['normal'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multicolinearity test after data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined_int[covariates].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Protein-phenotype associations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Run linear regression adjusting for covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# five covariates including age, sex, z_BMI.Nysom (BMI SDS, beta estimated seperately for normal and overweight (z_BMI.Nysom >=1.28)),\n",
    "# time_to_analysis (sample storage time), and pubertal_status2 (1=prepubertal, 2=pubertal/postpubertal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overweight/obesity (BMI SDS >= 1.28)\n",
    "data_combined_int['overweight'] = np.where(data_combined_int['z_BMI.Nysom']>=1.28, 1, 0)\n",
    "data_combined_int['normalweight'] = np.where(data_combined_int['z_BMI.Nysom']>=1.28, 0, 1)\n",
    "data_combined_int['overweight*z_BMI.Nysom']=data_combined_int['overweight']*data_combined_int['z_BMI.Nysom']\n",
    "data_combined_int['normalweight*z_BMI.Nysom']=data_combined_int['normalweight']*data_combined_int['z_BMI.Nysom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_lm =['sex', 'normalweight*z_BMI.Nysom','overweight*z_BMI.Nysom' , 'age', 'time_to_analysis', 'pubertal_status2', ]\n",
    "COVARIATES=covariates_lm\n",
    "RE_LIREG = False\n",
    "\n",
    "if not RE_LIREG:\n",
    "    lireg_statistics = pd.read_csv('results/association/lireg_statistics.csv')\n",
    "    lireg_residuals = pd.read_csv('results/association/lireg_residuals.csv').set_index('Sample ID')\n",
    "else:\n",
    "    lireg_statistics = []\n",
    "    lireg_residuals = {}\n",
    "    for protein in tqdm(proteins):\n",
    "        df = data_combined_int\n",
    "        df_test = df[[protein]+COVARIATES].dropna()\n",
    "        nr_obs = df_test.shape[0]\n",
    "        X=df_test[COVARIATES]\n",
    "        y=df_test[protein]\n",
    "        lm = pg.linear_regression(X=X, y=y,relimp=True )\n",
    "        lm['dep_var']=protein\n",
    "        lm['nr_obs']=nr_obs\n",
    "        residuals = pd.Series(lm.residuals_, index=df_test.index)\n",
    "        df_model = lm.df_model_\n",
    "        df_residual = lm.df_resid_\n",
    "        lm['df_model']=df_model\n",
    "        lm['df_residual']=df_residual\n",
    "        lireg_statistics.append(lm)\n",
    "        lireg_residuals[protein]=residuals\n",
    "    lireg_statistics = pd.concat(lireg_statistics)\n",
    "        \n",
    "    # FDR correction\n",
    "    reject, qvalue = multi.fdrcorrection(lireg_statistics['pval'], alpha=0.05, method='indep')\n",
    "    lireg_statistics['qvalue'] = qvalue\n",
    "    lireg_statistics['rejected'] = reject\n",
    "    \n",
    "    # Calculate -log10(pval)\n",
    "    lireg_statistics['-Log10 P-value'] = -np.log10(lireg_statistics['pval'])\n",
    "    \n",
    "    # Determine the direction of the coefficient\n",
    "    lireg_statistics['direction']=np.where(lireg_statistics['coef']>0, 'pos', 'neg')\n",
    "    \n",
    "    # Set direction as 'not significant' for non-rejected coefficients\n",
    "    lireg_statistics.loc[lireg_statistics['rejected']== False, 'direction']='not significant'  \n",
    "    \n",
    "    # Save results\n",
    "    lireg_statistics.to_csv('results/association/lireg_statistics.csv', index=False)\n",
    "    lireg_residuals = pd.DataFrame.from_dict(lireg_residuals)\n",
    "    lireg_residuals.rename_axis('Sample ID', axis=0, inplace=True)\n",
    "    lireg_residuals.to_csv('results/association/lireg_residuals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if regression results changed compared to previous run\n",
    "assert abs(lireg_residuals.loc['Plate5_1', 'Q9Y6Z7_COLEC10'] - -1.673965) < 0.00001, 'Regressed value changed in comparison to previous run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_BMI = {'overweight*z_BMI.Nysom':'z_BMI.Nysom', 'normalweight*z_BMI.Nysom':'z_BMI.Nysom'}\n",
    "lireg_statistics['names2'] = lireg_statistics['names'].replace(dict_BMI)\n",
    "\n",
    "# Extract significant associations\n",
    "lireg_statistics_sig = lireg_statistics[lireg_statistics.rejected]\n",
    "\n",
    "# Extract proteins associated with three factors\n",
    "factors_tokeep = ['sex', 'z_BMI.Nysom', 'age',]\n",
    "lireg_statistics_sig[lireg_statistics_sig['names2'].isin(factors_tokeep)]['dep_var'].nunique()\n",
    "lireg_statistics_sig['names2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to ease plotting\n",
    "lireg_dicts = {}\n",
    "for covariate in ['age', 'sex','z_BMI.Nysom']:\n",
    "    lireg_dicts[covariate] = {'df':lireg_statistics[lireg_statistics['names2']==covariate], \n",
    "                         'sig':lireg_statistics_sig[lireg_statistics_sig['names2']==covariate],\n",
    "                        'sig_set':set(lireg_statistics_sig[lireg_statistics_sig['names2']==covariate]['dep_var'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write results to supplementary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table1 = lireg_statistics_sig.copy()\n",
    "var_tokeep = ['z_BMI.Nysom', 'age', 'sex']\n",
    "col_todrop = ['rejected', 'direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table1 = df_table1[df_table1['names2'].isin(var_tokeep)].drop(col_todrop, axis=1).sort_values(by='names2')\n",
    "df_table1 = df_table1.reset_index().drop(['index'], axis=1)\n",
    "df_table1['Protein ID'] = df_table1['dep_var'].str.split('_').str[0]\n",
    "df_table1['Gene name'] = df_table1['dep_var'].str.split('_').str[1]\n",
    "df_table1 = df_table1.drop(['dep_var'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table1['names']=df_table1['names'].replace({'overweight*z_BMI.Nysom':'overweight*BMI-SDS',\n",
    "                                              'normalweight*z_BMI.Nysom':'normalweight*BMI-SDS'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_tokeep = ['Protein ID', 'Gene name', 'names', 'coef', 'se', 'T', 'pval', 'df_model', 'df_residual',\n",
    "               'r2', 'adj_r2', 'CI[2.5%]', 'CI[97.5%]',\n",
    "               'nr_obs', 'qvalue', '-Log10 P-value', ]\n",
    "headers_toreplace = ['Protein ID', 'Gene name', 'variable', 'coefficient', 'standard error', 'T-value', 'p-value', \n",
    "                    'degree of freedom_model', 'degree of freedom_residual', 'R square', 'adjusted R square', 'CI[2.5%]', 'CI[97.5%]',\n",
    "                    'observations', 'BH-corrected p-value', '-Log10 p-value']\n",
    "\n",
    "# Replace column headers\n",
    "new_names = dict(zip(cols_tokeep, headers_toreplace))\n",
    "df_table1_formatted = df_table1[cols_tokeep].rename(new_names, axis=1).sort_values(by=['variable', 'R square'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export data for Dash app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dash = lireg_statistics.copy()\n",
    "df_dash = df_dash[df_dash['names'].isin(['sex', 'normalweight*z_BMI.Nysom','overweight*z_BMI.Nysom','age'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dash = lireg_statistics.copy()\n",
    "df_dash = df_dash[df_dash['names'].isin(['sex', 'normalweight*z_BMI.Nysom','overweight*z_BMI.Nysom','age'])]\n",
    "df_dash = df_dash.rename(dict(zip(cols_tokeep, headers_toreplace)), axis=1)\n",
    "df_dash['p-value [-Log10]']=-np.log10(df_dash['p-value'])\n",
    "df_dash['BH-corrected p-value [-Log10]']=-np.log10(df_dash['BH-corrected p-value'])\n",
    "\n",
    "df_dash = df_dash[['dep_var', 'variable', 'coefficient', 'standard error','observations', 'p-value [-Log10]', 'BH-corrected p-value [-Log10]', 'rejected']]\n",
    "df_dash=df_dash.rename({'dep_var':'ProteinID_Genename', 'variable':'factor', 'rejected':'significant'}, axis=1)\n",
    "df_dash.to_csv('dash/dataset/dataset2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Characteristics of participants included in the phenotype-protein association analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined_int[['sex', 'age_int', 'z_BMI.Nysom', 'BMI', 'pubertal_status2']].groupby('sex')['pubertal_status2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined_int.dropna(subset=['pubertal_status2'])['overweight'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Data processing for protein-genotype association\n",
    "- Including puberty stage as a covariate results in losing >500 samples due to incomplete data. \n",
    "- In this step, we decided not to include puberty stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of covariates for pqtl analysis\n",
    "covariates_pqtl = ['sex', 'z_BMI.Nysom', 'age', 'time_to_analysis']\n",
    "\n",
    "# Alternative covariates that were tested but did not change the main results are commented out below\n",
    "#covariates_pqtl = ['sex', 'z_BMI.Nysom', 'age', 'time_to_analysis', 'overweight']\n",
    "#covariates_pqtl = ['sex', 'overweight*z_BMI.Nysom', 'normalweight*z_BMI.Nysom', 'age', 'time_to_analysis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVARIATES = covariates_pqtl\n",
    "RE_LIREG = False\n",
    "\n",
    "if not RE_LIREG:\n",
    "    lireg_statistics_pqtl = pd.read_csv('pQTL/gemma/lireg_statistics.csv')\n",
    "    lireg_residuals_pqtl = pd.read_csv('pQTL/gemma/lireg_residuals.csv').set_index('Sample ID')\n",
    "else:\n",
    "    lireg_statistics_pqtl = []\n",
    "    lireg_residuals_pqtl = {}\n",
    "    for protein in tqdm(proteins):\n",
    "        df = data_combined_int\n",
    "        df_test = df[[protein]+COVARIATES].dropna()\n",
    "        nr_obs = df_test.shape[0]\n",
    "        X=df_test[COVARIATES]\n",
    "        y=df_test[protein]\n",
    "        lm = pg.linear_regression(X=X, y=y,relimp=True )\n",
    "        lm['dep_var']=protein\n",
    "        lm['nr_obs']=nr_obs\n",
    "        residuals = pd.Series(lm.residuals_, index=df_test.index)\n",
    "        lireg_statistics_pqtl.append(lm)\n",
    "        lireg_residuals_pqtl[protein]=residuals\n",
    "    lireg_statistics_pqtl = pd.concat(lireg_statistics_pqtl)\n",
    "        \n",
    "    #FDR correction\n",
    "    reject, qvalue = multi.fdrcorrection(lireg_statistics_pqtl['pval'], alpha=0.05, method='indep')\n",
    "    lireg_statistics_pqtl['qvalue'] = qvalue\n",
    "    lireg_statistics_pqtl['rejected'] = reject\n",
    "    \n",
    "    # Calculate -log10(pval)\n",
    "    lireg_statistics_pqtl['-Log10 P-value'] = -np.log10(lireg_statistics_pqtl['pval'])\n",
    "    \n",
    "    # Determine the direction of the coefficient\n",
    "    lireg_statistics_pqtl['direction']=np.where(lireg_statistics_pqtl['coef']>0, 'pos', 'neg')\n",
    "    \n",
    "    # Set direction as 'not significant' for non-rejected coefficients\n",
    "    lireg_statistics_pqtl.loc[lireg_statistics_pqtl['rejected']== False, 'direction']='not significant'  \n",
    "    \n",
    "    # Save results\n",
    "    lireg_statistics_pqtl.to_csv('pQTL/gemma/lireg_statistics.csv', index=False)\n",
    "    lireg_residuals_pqtl = pd.DataFrame.from_dict(lireg_residuals_pqtl)\n",
    "    lireg_residuals_pqtl.rename_axis('Sample ID', axis=0)\n",
    "    lireg_residuals_pqtl.to_csv('pQTL/gemma/lireg_residuals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if regression results changed in comparison to previous run\n",
    "assert abs(lireg_residuals_pqtl.loc['Plate5_1', 'Q9Y6Z7_COLEC10'] - -1.6455972111247719) < 0.0001, 'Regressed value for GWAS changed in comparison to previous run'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform INT on residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_INT = False\n",
    "\n",
    "if not RE_INT:\n",
    "    data_gwas_int = pd.read_csv('pQTL/gemma/lireg_residuals_int.csv').set_index('Sample ID')\n",
    "else:\n",
    "    new_df = []\n",
    "    data = lireg_residuals_pqtl\n",
    "    for protein in tqdm(data.columns):\n",
    "        new_df.append(pd.DataFrame(rank_INT(data[protein], stochastic=False), columns=[protein]))\n",
    "    data_gwas_int = pd.concat(new_df, axis=1)\n",
    "    data_gwas_int.rename_axis('Sample ID', axis=0, inplace=True)\n",
    "    data_gwas_int.to_csv('pQTL/gemma/lireg_residuals_int.csv')\n",
    "\n",
    "# Check if normalization changed in comparison to previous run\n",
    "assert data_gwas_int.loc['Plate5_1', 'Q9Y6Z7_COLEC10'] == -1.6443417914920349, 'Normalized value for GWAS changed in comparison to previous run'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the data to fit the GEMMA input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace sample ID with participant ID so it's compatible with genotype data\n",
    "participant_ids = '66-' + data_gwas_int.index.map(IDmapping_SampleID_to_bloodSampleID)\n",
    "data_gwas_int.insert(0, 'Participant ID', participant_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the .fam file template\n",
    "fam_tep = pd.read_csv('pQTL/QC_PLINK/target5.fam', header=None, sep=' ')\n",
    "data_gwas_export = fam_tep.set_index(0).join(data_gwas_int.round(5).set_index('Participant ID')).reset_index().drop([5], axis=1)\n",
    "data_gwas_export.fillna('NA', inplace=True)\n",
    "\n",
    "# Check if data changed in comparison to previous run\n",
    "assert data_gwas_export.loc[0, 'A0A024R6I7_SERPINA1'] == 1.08161, 'Exported value for GWAS changed in comparison to previous run'\n",
    "\n",
    "# Export data for GWAS\n",
    "data_gwas_export.to_csv('pQTL/gemma/phenotype.fam', header=None, index=False, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe mapping phenotype IDs to protein IDs\n",
    "proteinID_pqtl=pd.DataFrame({'Phenotype ID':np.arange(1, 421),'Protein ID':data_gwas_export.columns[5:]})\n",
    "proteinID_pqtl.to_csv('pQTL/gemma/ProteinID.txt', index=False, sep='\\t')\n",
    "\n",
    "# Association performed in Computerome (GEMMA v0.98.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Export data to look at \"dose-response\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_plasma_filtered_log_imputed_corrected.copy()\n",
    "df.columns = '66-' + df.columns.map(IDmapping_SampleID_to_bloodSampleID)\n",
    "df.to_csv('pQTL/dose-response/data_log2_imputed.csv')\n",
    "\n",
    "df = data_plasma_filtered_log.copy()\n",
    "df.columns = '66-' + df.columns.map(IDmapping_SampleID_to_bloodSampleID)\n",
    "df.to_csv('pQTL/dose-response/data_log2.csv')\n",
    "\n",
    "df_cli = data_cli_prot[['sex', 'age_year']].dropna()\n",
    "df_cli['Participant ID'] = '66-' + df_cli.index.map(IDmapping_SampleID_to_bloodSampleID)\n",
    "df_cli = df_cli.set_index('Participant ID')\n",
    "df_cli.to_csv('pQTL/dose-response/data_cli.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export sample ID annotation for peptide data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotation_pep = annotation_file.copy()\n",
    "df_annotation_pep['Participant ID'] = '66-' + df_annotation_pep['Sample ID'].map(IDmapping_SampleID_to_bloodSampleID)\n",
    "df_annotation_pep.to_csv('pQTL/peptide_annotation.csv')\n",
    "\n",
    "# Peptide-level inspection was performed in Computerome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate datasets with doubling sample size from n=50\n",
    "- sample size: 50, 100, 200, 400, 800, 1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample, seed\n",
    "\n",
    "df = data_gwas_export.copy()\n",
    "sample_size = [50, 100, 200, 400, 800, 1600]\n",
    "indices = []\n",
    "sampleIDs = []\n",
    "\n",
    "# Set a seed for the random number generator to ensure reproducibility\n",
    "seed(42)\n",
    "\n",
    "for size in sample_size:\n",
    "    sampled_indices = sample(df.index.tolist(), size)\n",
    "    indices.append(sampled_indices)\n",
    "    df_new = df.copy()\n",
    "    df_new.loc[df.index.difference(sampled_indices), proteins]='NA'\n",
    "    df_new.to_csv('pQTL/gemma/sample_size/phenotype_{}.fam'.format(size), header=None, index=False, sep=' ')\n",
    "    \n",
    "    sampleID_list = df_new[0].tolist()\n",
    "    sampleIDs.append(sampleID_list)\n",
    "    df_new = df_new.replace('NA', np.nan)\n",
    "    normality_test_results = []\n",
    "    for protein in df_new.columns[5:]:\n",
    "        normal = pg.normality(np.array(df_new[df_new[protein]!='NA'][protein]))\n",
    "        normal['protein']=protein\n",
    "        normality_test_results.append(normal)\n",
    "    print(pd.concat(normality_test_results)['normal'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Prepare genotype array batch data for use as covariates ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import batch info\n",
    "df_batch = pd.read_csv('pQTL/ids_in_batch.txt', sep=' ', header=None, names=['participant ID', 'batch'])\n",
    "onehot_batch = pd.DataFrame(pd.get_dummies(df_batch['batch']))\n",
    "onehot_batch['participant ID']=df_batch['participant ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine participant IDs and genotype array batch data as covariates\n",
    "data_gwas_covariates = fam_tep[[0]].set_index(0).join(onehot_batch.set_index('participant ID')).drop(['batch2015'], axis=1)\n",
    "\n",
    "# Add an intercept column to the covariate data\n",
    "data_gwas_covariates.insert(0, 'intercept', 1)\n",
    "\n",
    "# Replace missing values with 'NA'\n",
    "data_gwas_covariates = data_gwas_covariates.fillna('NA')\n",
    "\n",
    "# Select rows where the batch2018 column has missing values\n",
    "data_gwas_covariates[data_gwas_covariates['batch2018']=='NA']\n",
    "\n",
    "# Save the covariate data to a tab-separated text file for use with GEMMA\n",
    "data_gwas_covariates.to_csv('pQTL/gemma/covariates.txt', header=None, index=False, sep=' ')\n",
    "\n",
    "# Generate covariate file used in GWAS for different sample sizes\n",
    "for size, IDlist in (zip(sample_size, sampleIDs)):\n",
    "    df=data_gwas_covariates.copy()\n",
    "    df_new = df.loc[IDlist]\n",
    "    df_new.to_csv('pQTL/gemma/sample_size/covariates_{}.txt'.format(size), header=None, index=False, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size, IDlist in (zip(sample_size, sampleIDs)):\n",
    "    df=data_gwas_covariates.copy()\n",
    "    df_new = df.loc[IDlist]\n",
    "    df_new.to_csv('pQTL/gemma/sample_size/covariates_{}.txt'.format(size), header=None, index=False, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check sex discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the PLINK sexcheck file and merge with clinical data\n",
    "df_sex = pd.read_csv('pQTL/QC_PLINK/plink.sexcheck', sep='\\s+')\n",
    "df_sex['biobank_ID']=df_sex['FID'].str.split('-').str[1]\n",
    "df_sex = df_sex.merge(data_cli_raw[['biobank_ID', 'sex']], on='biobank_ID', how='left')\n",
    "\n",
    "# Select rows where the SNPSEX column does not match the sex column from clinical data\n",
    "df_sex[df_sex['SNPSEX']!=df_sex['sex']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we predict age and BMI based on plasma proteome? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data, outcome_col, predictors, stratify_col):\n",
    "    if outcome_col!=stratify_col:\n",
    "        df=data[predictors + [outcome_col, stratify_col]].dropna()\n",
    "    else:\n",
    "        df=data[predictors + [outcome_col]].dropna()\n",
    "    X=df[predictors]\n",
    "    y=df[outcome_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, \n",
    "                                                       stratify=df[stratify_col]\n",
    "                                                       )\n",
    "    X_train_train, X_train_validation, y_train_train, y_train_validation = train_test_split(X_train, y_train, \n",
    "                                                                                            test_size=0.3, \n",
    "                                                                                            random_state=42,\n",
    "                                                                                           stratify=df[stratify_col].loc[X_train.index]\n",
    "                                                                                           )\n",
    "    return X_train_train, X_train_validation, X_test, y_train_train, y_train_validation, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get beta coefficients for features in training set\n",
    "def get_features(outcome_col='age', predictors=proteins, stratify_col='age_int', data=data_combined):\n",
    "    X_train_train, X_train_validation, X_test, y_train_train, y_train_validation, y_test = get_data(data=data, outcome_col=outcome_col, \n",
    "                                                                                                   predictors=predictors, stratify_col=stratify_col)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_train, y_train_train)\n",
    "    feature_coef = pd.DataFrame(model.coef_, columns=['beta coef. (lm)'])\n",
    "    feature_coef['features'] = X_train_train.columns\n",
    "    feature_coef['abs(coef)'] = abs(feature_coef['beta coef. (lm)'])\n",
    "    feature_coef = feature_coef.set_index('features').sort_values(by='abs(coef)', ascending=False)\n",
    "    \n",
    "    #iterating number of features from 1-total, record mean squared errors on validation set\n",
    "    mses = []\n",
    "    for i in tqdm(np.arange(1, feature_coef.shape[0]+1)):\n",
    "        selected_features = feature_coef.iloc[:i].index\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train_train[selected_features], y_train_train)\n",
    "        y_pred_validation = model.predict(X_train_validation[selected_features])\n",
    "        mse = mean_squared_error(y_train_validation, y_pred_validation)\n",
    "        mses.append(mse)\n",
    "    sme_vs_features = pd.DataFrame(mses, columns=['Squared mean error'])\n",
    "    sme_vs_features['Nr. features']=np.arange(1, sme_vs_features.shape[0]+1)\n",
    "    sme_vs_features['features'] = feature_coef.index\n",
    "    sme_vs_features.set_index('features', inplace=True)\n",
    "    combined = feature_coef.join(sme_vs_features)\n",
    "    nr_of_features = int(combined[combined['Squared mean error']==combined['Squared mean error'].min()].iloc[0]['Nr. features'])\n",
    "    nr_of_features = nr_of_features if nr_of_features < 80 else 80\n",
    "    features = combined.index[:nr_of_features]\n",
    "    return (features, combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_age, df_features_age = get_features()\n",
    "features_bmi, df_features_bmi = get_features(outcome_col='BMI', stratify_col = 'bin_numbers_bmi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_score(outcome_col, data, predictors, features, stratify_col):\n",
    "    X_train_train, X_train_validation, X_test, y_train_train, y_train_validation, y_test = get_data(outcome_col=outcome_col, data=data,\n",
    "                                                                                                       predictors=predictors, stratify_col=stratify_col)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_train[features], y_train_train)\n",
    "    coef = model.coef_\n",
    "    y_pred_test = model.predict(X_test[features])\n",
    "    corr, pvalue = pearsonr(y_test, y_pred_test)\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    pred_score = pd.DataFrame.from_dict({'Pearson r': corr.round(2), 'mean_squared_error':mse.round(1),\n",
    "                                         'mean_absolute_error':mae.round(1)},\n",
    "                                          orient='index', columns=[outcome_col])\n",
    "    pred = pd.DataFrame(y_test)\n",
    "    pred['y_pred'] = y_pred_test\n",
    "    \n",
    "    return(pred, pred_score, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction values and scores for age\n",
    "pred_age, pred_score_age, coef_age = get_prediction_score('age', data_combined, proteins, features_age, 'age_int')\n",
    "\n",
    "# Get prediction values and scores for BMI\n",
    "pred_bmi, pred_score_bmi, coef_bmi = get_prediction_score('BMI', data_combined, proteins, features_bmi, 'bin_numbers_bmi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export supplementary tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table2_age = pd.DataFrame.from_dict({'predictors for age':features_age, \n",
    "                                       'coefs':coef_age})\n",
    "df_table2_bmi = pd.DataFrame.from_dict({'predictors for BMI':features_bmi, \n",
    "                                       'coefs':coef_bmi})\n",
    "df_table2 = pd.concat([df_table2_age, df_table2_bmi], ignore_index=True, axis=1)\n",
    "df_table2.columns = ['predictors for age (UniprotID_Genename)', 'coefficient', \n",
    "                     'predictors for BMI (UniprotID_Genename)','coefficient' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdrive_dir = '/Volumes/jpx667/Projects/TARGET'\n",
    "#df_table3 = pd.read_csv(os.path.join(pdrive_dir, 'Perseus/protein_age_clusters.txt'), sep='\\t')\n",
    "df_table3 = pd.read_csv('tables/protein_age_clusters.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = {'Cluster -156':'Cluster1', 'Cluster -152':'Cluster2', \n",
    "                'Cluster -142':'Cluster3','Cluster -149':'Cluster4', \n",
    "                'Cluster -124':'Cluster5', 'Cluster -99':'Cluster6', \n",
    "                'Cluster -162':'Cluster7'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table3['Cluster2'] = df_table3['Cluster'].map(cluster_dict)\n",
    "df_table3['Cluster2']=df_table3['Cluster2'].fillna('Unclassified')\n",
    "df_table3 = df_table3[1:].drop(['Cluster'], axis=1).sort_values(by='Cluster2').rename({'Cluster2':'Cluster'}, axis=1)\n",
    "df_table3 = df_table3.reset_index().drop('index', axis=1)\n",
    "df_table3 = df_table3.set_index(['Cluster', 'Protein ID', 'Gene name']).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index = df_table3.index\n",
    "new_cols = pd.MultiIndex.from_tuples([('boys', i) for i in np.arange(5, 20)] + \n",
    "                                     [('girls', i) for i in np.arange(5, 21)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table3_formatted = pd.DataFrame(df_table3.values, index=new_index, columns=new_cols)\n",
    "df_table3_formatted = df_table3_formatted.rename_axis(['sex', 'age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table6 = pd.read_excel('tables/TableS6.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write table 1-3, and 6 to supplementary tables\n",
    "with pd.ExcelWriter('tables/Supplementary_tables.xlsx') as writer:\n",
    "    df_table1_formatted.to_excel(writer,sheet_name='ST1', index=False)\n",
    "    df_table2.to_excel(writer,sheet_name='ST2', index=False)\n",
    "    df_table3_formatted.to_excel(writer, sheet_name='ST3')\n",
    "    df_table6.to_excel(writer, sheet_name='ST6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "sns.set_style('ticks')\n",
    "fig, axes = plt.subplots(3,3, figsize=(16,16))\n",
    "FACTORS = ['age', 'z_BMI.Nysom', 'sex']\n",
    "dfs=[lireg_dicts[i]['df'] for i in FACTORS]\n",
    "axes[1, 0].set_title('Age associated proteome', fontsize=14)\n",
    "axes[1, 1].set_title('BMI associated proteome', fontsize=14)\n",
    "axes[1, 2].set_title('Sex associated proteome', fontsize=14)\n",
    "axs = axes.flat\n",
    "for n, ax in enumerate(axs):\n",
    "    ax.text(-0.2, 1.1, string.ascii_lowercase[n], transform=ax.transAxes, size=15, weight='bold')\n",
    "    \n",
    "for i in range(3):\n",
    "    panel2 = sns.scatterplot(ax=axes[1, i], x='coef', y='-Log10 P-value', data=dfs[i], hue='direction',\n",
    "                size='-Log10 P-value', palette = {'not significant':'gray', 'pos':'darkred', 'neg':'royalblue'},\n",
    "                legend=False, alpha=1, edgecolor='white')\n",
    "    panel2.set(xlim=(-1, 1))\n",
    "    \n",
    "for i in range(3):\n",
    "    for j in range(3):        \n",
    "        axes[i, j].tick_params(axis='x', labelsize=13)\n",
    "        axes[i, j].tick_params(axis='y', labelsize=13)\n",
    "        axes[i, j].xaxis.label.set_size(fontsize=13)\n",
    "        axes[i, j].yaxis.label.set_size(fontsize=13)\n",
    "\n",
    "subsets = [set(lireg_dicts[i]['sig_set']) for i in FACTORS]\n",
    "venn3(ax=axes[0,1], subsets=subsets, set_labels=('Age', 'BMI', 'Sex'), \n",
    "      set_colors=('white', 'steelblue', 'red'))\n",
    "venn3_circles(ax=axes[0,1], subsets=subsets, linewidth=0.8);\n",
    "\n",
    "c=sns.stripplot(ax=axes[0,2], x='names2', y='coef', data=lireg_statistics_sig[lireg_statistics_sig['names2'].isin(FACTORS)], palette = dict(zip(FACTORS, ['white', 'steelblue', 'pink'])), \n",
    "                       alpha=1, edgecolor='black', linewidth=0.5, size=5)\n",
    "\n",
    "x='age'\n",
    "y='y_pred'\n",
    "data=pred_age\n",
    "score = pred_score_age\n",
    "h=sns.scatterplot(ax=axes[2,1], x=x, y=y, data=data, color='steelblue', edgecolor='black')\n",
    "h=sns.regplot(ax=axes[2,1], x=x, y=y, data=data, scatter=False, color='darkred')\n",
    "h.set(xlim=(4.6, 20.6), ylim=(4.6,20.6), xticks=np.arange(3,11)*2)\n",
    "h.annotate('Test dataset (n={})\\nPearson: {}\\nMean absolute error:{}'.format(data.shape[0],score.loc['Pearson r'][x], score.loc['mean_absolute_error'][x]), \n",
    "           xycoords='axes fraction', xy=(0.02, 0.8), fontsize=13)\n",
    "x='BMI'\n",
    "data=pred_bmi\n",
    "score = pred_score_bmi\n",
    "i=sns.scatterplot(ax=axes[2,2], x=x, y=y, data=data, color='steelblue', edgecolor='black')\n",
    "i=sns.regplot(ax=axes[2,2], x=x, y=y, data=data, scatter=False, color='darkred')\n",
    "i.set(xlim=(10, 50), ylim=(10,50))\n",
    "i.annotate('Test dataset (n={})\\nPearson: {}\\nMean absolute error:{}'.format(data.shape[0],score.loc['Pearson r'][x], score.loc['mean_absolute_error'][x]), \n",
    "           xycoords='axes fraction', xy=(0.02, 0.8), fontsize=13)\n",
    "\n",
    "\n",
    "\n",
    "axes[0, 0].axis('off')\n",
    "axes[2, 0].axis('off')\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "plt.savefig('figures/figure 2.pdf', dpi=120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore associations\n",
    "FACTORS = ['age', 'z_BMI.Nysom', 'sex']\n",
    "dfs=[lireg_dicts[i]['df'] for i in FACTORS]\n",
    "px.scatter(x='coef', y='-Log10 P-value', data_frame=lireg_dicts['z_BMI.Nysom']['df'], hover_name='dep_var')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2 - Trajectories of age associated proteins\n",
    "- export to Perseus to generate heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_age = lireg_dicts['age']['sig_set']\n",
    "#sig_puberty = lireg_dicts['pubertal_status2']['sig_set']\n",
    "sig_age_proteins = list(set(proteins) & set(sig_age))\n",
    "df_age = data_combined.groupby(['sex', 'age_int']).median()[sig_age_proteins].T.dropna(axis=0)\n",
    "df_age['Gene name']=df_age.index.str.split('_').str[1]\n",
    "df_age['Protein ID']=df_age.index.str.split('_').str[0]\n",
    "\n",
    "df_sig_age = lireg_dicts['age']['sig']\n",
    "df_sig_age.loc[:, 'abs(coef)']=abs(df_sig_age['coef'])\n",
    "toplot_proteins = df_sig_age[df_sig_age['abs(coef)']>0.04]['dep_var'].tolist()\n",
    "\n",
    "df_age.to_csv('data/processed/age_sig.csv')\n",
    "df_age.loc[toplot_proteins].to_csv('data/processed/age_sig_coef.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplot=['I3L145_SHBG', 'P01023_A2M', 'P06276_BCHE', 'E7ES19_THBS4',\n",
    "       'P02741_CRP', 'P18428_LBP', 'P02790_HPX', 'P04004_VTN', 'P35858_IGFALS','A6XND0_IGFBP3', 'A0A087WWU8_TPM3', 'P62736_ACTA2',\n",
    "        'P20742_PZP', 'P01019_AGT', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(7, 2, figsize=(4,12))\n",
    "fig.subplots_adjust(hspace=0.6, wspace=0.8)\n",
    "n=1\n",
    "for (ax, protein) in zip(axs.flat, toplot):\n",
    "    ax.text(-0.7, 1.05, string.ascii_lowercase[n], transform=ax.transAxes, weight='bold')\n",
    "    n+=1\n",
    "    sns.lineplot(x='age_int', y=protein, data=data_combined, \n",
    "                 hue='sex', palette=['darkred', 'darkblue'], ax=ax, legend=False)\n",
    "    genename=protein.split('_')[1]\n",
    "    ax.set_title(genename)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('MS signal\\n[Log2]')\n",
    "    ax.set_xticks([5*i for i in np.arange(1, 5)])\n",
    "    ax.set_ylim(ax.get_ylim()[0]*0.97, ax.get_ylim()[1]*1.03)\n",
    "    \n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "fig.savefig('figures/figure2.pdf', dpi=120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
